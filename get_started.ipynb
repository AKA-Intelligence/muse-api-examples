{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started\n",
    "\n",
    "In this notebook, we are going to explore some of the functionalities that Muse API provides and build some example chatbot applications with a focus on natural conversation.\n",
    "\n",
    "For a quick intro on machine learning approaches to building chatbots, [this](http://www.wildml.com/2016/04/deep-learning-for-chatbots-part-1-introduction/) is a good primer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval based model\n",
    "\n",
    "We will start with an example of how we can build a retrieval based chatbot using Muse API.\n",
    "\n",
    "Muse API provides access to a number of data sources from which you can retrieve potential responses for a given user input. The url for this function is `/api/chat/retrieval/`. Let's `import` a wrapper function that sends a request and returns the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from muse import get_candidate_responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `get_candidate_responses` function takes two arguments, `sent`, and `source`. The `sent` argument is the sentence to which we want to retrieve candidate responses for, and the `source` argument specifies from which data source the responses come. At the moment, there are three data sources, which you can access by setting the `source` argument to one of `[1,2,3]`. Let's retrieve potential responses for the sentence **\"What did you last weekend?\"** from data source `3` and print the similarity score and the response text of the first five candidates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.7690440580433996, u'I went to a festival was such a good time')\n",
      "(0.5524923548780294, u'I watched the new Star Wars Movie Rogue One!')\n",
      "(0.5524923548780294, u'Oh, I just sat home on the couch watching tv.')\n",
      "(0.5336215919403026, u'Oh I just stayed in bed and watched Aladdin.')\n",
      "(0.5212465751011512, u'I went to go see a concert at The National.')\n"
     ]
    }
   ],
   "source": [
    "candidate_responses = get_candidate_responses(\"what did you last weekend?\",source=3)\n",
    "for candidate in candidate_responses[:5]:\n",
    "    print(candidate['score'], candidate['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can simply return the candidate response with the highest score (the candidates are ordered in the list by descending similarity score), and build a super simple retrieval based chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User> hey\n",
      "Bot> Hey man\n",
      "User> what did you do last weekend?\n",
      "Bot> I went to a festival was such a good time\n",
      "User> what festival did you go to?\n",
      "Bot> I went to the cineplex 8 and the fairview mall.\n",
      "User> do they show movies or something?\n",
      "Bot> I like war movies?\n",
      "User> i don't know.\n",
      "Bot> That sounds like a live version? Is it?\n",
      "User> maybe\n",
      "Bot> Well who knows\n",
      "User> you should know because you went to the festival\n",
      "Bot> Oh yes!  I went to see the GoGos perform at a small college in Illinois. I think I was about 18 at the time?\n",
      "User> who are the GoGos?\n",
      "Bot> Well, let's see, Reggie Miller, Steve Nash, Larry Bird, to name a few, and that's shooters who also played defense.\n",
      "User> so it's a basketball team?\n",
      "Bot> I like the New York Rockets?\n",
      "User> maybe?\n",
      "Bot> Just listen to them.  Nothing THAT unique\n",
      "User> bye\n",
      "Bot> Alright, see you later.\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    user_text = raw_input(\"User> \")\n",
    "    if user_text.lower().strip() in ['quit','stop','bye']:\n",
    "        print(\"Bot> Alright, see you later.\")\n",
    "        break\n",
    "    candidates = get_candidate_responses(user_text,source=3)\n",
    "    bot_response = candidates[0]['text']\n",
    "    print(\"Bot> %s\"%bot_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Comprehension\n",
    "\n",
    "Now, let's make a bot that responds to\n",
    "1. statements with a simple \"Okay.\", and \n",
    "2. questions using the machine comprehension model on previous user statements.\n",
    "\n",
    "So the flow we have in mind is the following. The user utters several statements, and when the user asks a question at the end, the chatbot tries to answer the question based on what the user said. \n",
    "\n",
    "First, let's import the wrapper function that does machine comprehension.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from muse import comprehend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `comprehend` function takes two arguments, `passage`, and `question`, and returns the answer to the question about the passage. Let's try it out quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skyrim\n"
     ]
    }
   ],
   "source": [
    "passage = \"My favorite video game is Skyrim.\"\n",
    "question = \"What video game do I like to play?\"\n",
    "answer = comprehend(passage,question)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, we need a helper function that will determine whether a given user utterance is a statement or a question. So let's make a super simple function that checks whether the first word of the user utterance is a usual first word in questions, like 'why','what','when',etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_question(utterance):\n",
    "    question_start_tokens = ['what','how','where','who','why','which','when']\n",
    "    first_token = utterance.split()[0].lower()\n",
    "    if first_token in question_start_tokens:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User> my parents live in Busan.\n",
      "Bot> Okay.\n",
      "User> my parents are in their 50s.\n",
      "Bot> Okay.\n",
      "User> my dad is older than my mom by one year.\n",
      "Bot> Okay.\n",
      "User> how much older is my dad than my mom?\n",
      "Bot> by one year\n",
      "User> where do my parents live?\n",
      "Bot> Busan\n",
      "User> how old are my parents?\n",
      "Bot> 50s\n",
      "User> my father is a music teacher.\n",
      "Bot> Okay.\n",
      "User> my mother is a family therapist.\n",
      "Bot> Okay.\n",
      "User> what does my father do?\n",
      "Bot> a music teacher\n",
      "User> what does my mother do?\n",
      "Bot> a family therapist\n",
      "User> my brother is in the military.\n",
      "Bot> Okay.\n",
      "User> i am sad because my brother is in the military.\n",
      "Bot> Okay.\n",
      "User> where is my brother?\n",
      "Bot> in the military\n",
      "User> why am i sad?\n",
      "Bot> my brother is in the military\n",
      "User> bye\n",
      "Bot> Alright, see you later.\n"
     ]
    }
   ],
   "source": [
    "user_utts_hist = []\n",
    "while True:\n",
    "    user_text = raw_input(\"User> \")\n",
    "    if user_text.lower().strip() in ['quit','stop','bye']:\n",
    "        print(\"Bot> Alright, see you later.\")\n",
    "        break\n",
    "    \n",
    "    if is_question(user_text):\n",
    "        answer = comprehend(' '.join(user_utts_hist),user_text)\n",
    "        print(\"Bot> %s\"%answer)\n",
    "    else:\n",
    "        user_utts_hist.append(user_text)\n",
    "        print(\"Bot> Okay.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coreference Resolution\n",
    "\n",
    "Let's improve the above code, so that we don't have to keep saying my parents, my father, my mother, my brother, etc. everytime and instead say they, he, she, etc. For this we are going to use the coreference resolution feature provided by Muse API. The wrapper function is `coreference_resolution`. It takes two arguments, `context`,and `utterance`. Both are strings, and it will resolve any occurances of \"reference words\" in the `utterance` with appropriate noun chunks from `utterance`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from muse import coreference_resolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try it out quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sometimes my mom gets mad at my dad.\n"
     ]
    }
   ],
   "source": [
    "context = \"my mom is a family therapist. my dad is a music teacher.\"\n",
    "utterance = \"sometimes she gets mad at him.\"\n",
    "resolved = coreference_resolution(context,utterance)\n",
    "print(resolved)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, so good. Let's try and put it into our comprehension bot. We should set a limit on how far back into the past utterances to search for noun chunks to replace the pronouns in a given utterance. Let's set this number to 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User> my dad is a music teacher.\n",
      "Bot> Okay.\n",
      "User> my mother is a family therapist.\n",
      "Bot> Okay.\n",
      "User> sometimes she gets mad at him.\n",
      "Bot> Okay.\n",
      "User> who does she get mad at?\n",
      "Bot> my dad\n",
      "User> what does he do?\n",
      "Bot> a music teacher\n",
      "User> bye\n",
      "Bot> Alright, see you later.\n"
     ]
    }
   ],
   "source": [
    "COREF_UTTS_WINDOW = 3\n",
    "user_utts_hist = []\n",
    "while True:\n",
    "    user_text = raw_input(\"User> \")\n",
    "    if user_text.lower().strip() in ['quit','stop','bye']:\n",
    "        print(\"Bot> Alright, see you later.\")\n",
    "        break\n",
    "    \n",
    "    coref_context = ' '.join(user_utts_hist[-COREF_UTTS_WINDOW:])\n",
    "    resolved_user_utts = coreference_resolution(coref_context,user_text)\n",
    "    if is_question(user_text):\n",
    "        answer = comprehend(' '.join(user_utts_hist),resolved_user_utts)\n",
    "        print(\"Bot> %s\"%answer)\n",
    "    else:\n",
    "        user_utts_hist.append(resolved_user_utts)\n",
    "        print(\"Bot> Okay.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
